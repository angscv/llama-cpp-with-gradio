llama-cpp-python
gradio
requests
python-dotenv
fire
fschat
accelerate
autoawq
vllm
